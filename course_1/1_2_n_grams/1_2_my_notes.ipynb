{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lab: Experiment With N-Gram Models\n",
    "## Purpose:\n",
    "- Estimate next-word probabilities programmatically\n",
    "- Build a (small) n-gram model on a (tiny) dataset.\n",
    "- Understand n-gram models & their limitations\n",
    "### Topics:\n",
    "- Tokenization\n",
    "- Probability estimation\n",
    "- Token prediction\n",
    "\n",
    "Date: 2026-02-18\n",
    "\n",
    "Source: https://colab.research.google.com/github/google-deepmind/ai-foundations/blob/master/course_1/gdm_lab_1_2_experiment_with_n_gram_models.ipynb\n",
    "\n",
    "References: https://github.com/google-deepmind/ai-foundations\n",
    "- GDM GH repo used in AI training courses at the university & college level."
   ],
   "id": "96ce43ec4b3ab3a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Understanding the math\n",
    "**N-gram**: A continuous sequence of $n$ words.\n",
    "\n",
    "**Context**: The preceding sequence of $n-1$ words.\n",
    "\n",
    "**How are n-grams related to the context?** N-gram models use n-grams to estimate the probability of the next word based on the context.\n",
    "\n",
    "**Text Corpus**: A dataset consisting of a collection of texts\n",
    "\n",
    "Computing the Probability of the next word\n",
    "---\n",
    "Given $\\mbox{A}$ is the context\n",
    "\n",
    "Given $\\mbox{B}$ is the next word\n",
    "\n",
    "Compute the probability $P(\\mbox{B} \\mid \\mbox{A})$:\n",
    "\n",
    "$$P(\\mbox{B} \\mid \\mbox{A}) = \\frac{\\mbox{Count}(\\mbox{A B})}{\\mbox{Count}(\\mbox{A})}$$\n",
    "\n",
    "The full n-gram counts, $\\mbox{ Count}(\\mbox{A B})$, and the context n-gram counts, $\\mbox{ Count}(\\mbox{A})$, can be computed by counting n-grams in a dataset (**text corpus**)."
   ],
   "id": "ea6e8358739e0bae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Set up the local environment\n",
    "See `environment_setup.md` for detailed instructions.\n",
    "\n",
    "Quick setup (if running in Colab or a fresh environment):"
   ],
   "id": "53edebe92b23784f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install the AI Foundations package directly from GitHub\n",
    "# %pip install \"git+https://github.com/google-deepmind/ai-foundations.git@main\"\n",
    "# Or use the requirements file if available\n",
    "try:\n",
    "    import numpy as np\n",
    "    import ai_foundations\n",
    "    print(\"ai_foundations is already installed.\")\n",
    "except ImportError:\n",
    "    print(\"Installing ai_foundations...\")\n",
    "    %pip install \"git+https://github.com/google-deepmind/ai-foundations.git@main\""
   ],
   "id": "258ea9ae143f1304",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Packages used.\n",
    "import random           # For sampling from probability distributions.\n",
    "from collections import Counter, defaultdict # For counting n-grams.\n",
    "\n",
    "import textwrap         # For automatically adding linebreaks to long texts.\n",
    "import pandas as pd     # For construction and visualizing tables.\n",
    "\n",
    "# Custom functions for providing feedback on your solutions.\n",
    "# from ai_foundations.feedback.course_1 import ngrams\n",
    "import ai_foundations\n",
    "from ai_foundations.feedback.course_1 import ngrams"
   ],
   "id": "7271a2fd246bae25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Africa Galore dataset\n",
    "Specialized dataset containing information on African culture, history, & geography generated by Gemini. The use of Gemini to create the dataset is supposed to ensure clean data by removing noise and inconsistencies."
   ],
   "id": "a6ff571dbe21f1bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "africa_galore = pd.read_json(\n",
    "    \"https://storage.googleapis.com/dm-educational/assets/ai_foundations/africa_galore.json\"\n",
    ")\n",
    "dataset = africa_galore[\"description\"]\n",
    "# pd.DataFrame.shape() returns row counts and column counts\n",
    "# len() only provides row counts.\n",
    "print(f\"The dataset consists of {dataset.shape[0]} paragraphs.\")"
   ],
   "id": "b4eaff1acb3cc97f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Inspect first 10 paragraphs in dataset\n",
    "for paragraph in dataset[:10]:\n",
    "    # textwrap automatically adds linebreaks to make long texts more readable.\n",
    "    formatted_paragraph = textwrap.fill(paragraph)\n",
    "    print(f\"{formatted_paragraph}\\n\")"
   ],
   "id": "a64361616438845a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### About Tokenization\n",
    "The above paragraphs are a single continuous string. The next function will split the strings on spaces to produce tokens; however, splitting on spaces does not take punctuation into account; therefore, a token may be the same as a word, but not always."
   ],
   "id": "28d93125bea1b859"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_tokens(text: str) -> list[str]:\n",
    "    \"\"\"Splits a string on space to create list of tokens.\n",
    "    Args:\n",
    "        text: The input text.\n",
    "    Returns:\n",
    "        Lst of tokens. Returns empty list if text is empty or all spaces.\n",
    "    \"\"\"\n",
    "    tokens = text.split(\" \")\n",
    "    return tokens\n",
    "\n",
    "# Tokenize an example text.\n",
    "create_tokens(\"Kanga, a colorful printed cloth is more than just a fabric.\")"
   ],
   "id": "bb7e80f79a9d16d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Output will be a list of the words in a sentence. Nothing fancy.\n",
    ">```\n",
    ">['Kanga,',\n",
    "> 'a',\n",
    "> 'colorful',\n",
    "> 'printed',\n",
    "> 'cloth',\n",
    "> 'is',\n",
    "> 'more',\n",
    "> 'than',\n",
    "> 'just',\n",
    "> 'a',\n",
    "> 'fabric.']"
   ],
   "id": "a8dacb694579caa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# test it on the entire dataset.\n",
    "create_tokens(dataset[0])"
   ],
   "id": "3074a0a321ccdfb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Coding activity 1\n",
    "create_tokens() creates a list of tokens; however, the conditional probability of any token $\\mbox{B}$ following the preceding context $\\mbox{A}$, $P(\\mbox{B} \\mid \\mbox{A})$, relies on how often any **n-grams** and **(n-1)-grams** appear in the dataset.\n",
    "\n",
    "---\n",
    "- The function generate_ngrams() will be called once for each paragraph in the dataset.\n",
    "    - It takes a paragraph and an integer to create n-grams of the length of the integer.\n",
    "- Use create_tokens() to create a list of n-grams of length *n* for a text.\n",
    "- Represent each n-gram as a tuple using tuple()."
   ],
   "id": "3199fc3cbadc29f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_unigrams = []\n",
    "all_bigrams = []\n",
    "all_trigrams = []\n",
    "\n",
    "def generate_ngrams(text: str, n: int) -> list[tuple[str]]:\n",
    "    \"\"\"Generates n-grams from a given text.\n",
    "    Args:\n",
    "        text: The input text string.\n",
    "        n: The size of the n-grams (e.g., 2 for bigrams, 3 for trigrams).\n",
    "    Returns:\n",
    "        A list of n-grams, each represented as a list of tokens.\n",
    "    \"\"\"\n",
    "    # Tokenize text.\n",
    "    # My code below\n",
    "    tokens = create_tokens(text)\n",
    "\n",
    "    # Construct the list of n-grams.\n",
    "    ngrams = []\n",
    "    num_of_tokens = len(tokens)\n",
    "\n",
    "    # The last n-gram will be tokens[num_of_tokens - n + 1: num_of_tokens + 1].\n",
    "    for i in range(0, num_of_tokens - n + 1):\n",
    "        ngrams.append(tuple(tokens[i:i+n]))\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "# This is hard-coded as an example for the student to understand the process.\n",
    "for paragraph in dataset:\n",
    "    # Calling `generate_ngrams` with n=1 constructs a list of unigrams.\n",
    "    all_unigrams.extend(generate_ngrams(paragraph, n=1))\n",
    "    # Calling `generate_ngrams` with n=2 constructs a list of bigrams (2-grams).\n",
    "    all_bigrams.extend(generate_ngrams(paragraph, n=2))\n",
    "    # Calling `generate_ngrams` with n=2 constructs a list of trigram (3-grams).\n",
    "    all_trigrams.extend(generate_ngrams(paragraph, n=3))\n",
    "\n",
    "print(\"First 10 Unigrams:\", all_unigrams[:10])\n",
    "print(\"First 10 Bigrams:\", all_bigrams[:10])\n",
    "print(\"First 10 Trigrams:\", all_trigrams[:10])"
   ],
   "id": "73918156007e1217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# testing function built into the ngrams library\n",
    "ngrams.test_generate_ngrams(generate_ngrams, create_tokens)"
   ],
   "id": "4a542e3580a52e65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Special case of n-gram counts for bigrams & trigrams\n",
    "Using the Python Counter datatype\n",
    "See: https://docs.python.org/3/library/collections.html#collections.Counter and\n",
    "https://docs.python.org/3/library/collections.html#collections.defaultdict"
   ],
   "id": "af2687d09e11cb6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "bigram_counts = Counter(all_bigrams)\n",
    "\n",
    "# Print the ten most common bigrams.\n",
    "print(\"Most common bigrams:\")\n",
    "for bigram, count in bigram_counts.most_common(10):\n",
    "    print(f\"  ({bigram}, {count})\")\n",
    "\n",
    "# Use the Python Counter data type for computing the counts of all trigrams.\n",
    "trigram_counts = Counter(all_trigrams)\n",
    "\n",
    "# Print the ten most common trigrams.\n",
    "print(\"\\n\\nMost common trigrams:\")\n",
    "for trigram, count in trigram_counts.most_common(10):\n",
    "    print(f\"  ({trigram}, {count})\")"
   ],
   "id": "427a8b37a81c3c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Most common bigrams:\n",
    ">```\n",
    ">  (('is', 'a'), 144)\n",
    ">  (('of', 'the'), 100)\n",
    ">  (('and', 'the'), 69)\n",
    ">  (('in', 'the'), 61)\n",
    ">  (('with', 'a'), 60)\n",
    ">  (('in', 'a'), 55)\n",
    ">  (('and', 'a'), 50)\n",
    ">  (('to', 'the'), 42)\n",
    ">  (('was', 'a'), 39)\n",
    ">  (('It', 'is'), 33)\n",
    "\n",
    "\n",
    "Most common trigrams:\n",
    ">```\n",
    ">  (('went', 'looking', 'for'), 32)\n",
    ">  (('a', 'symbol', 'of'), 18)\n",
    ">  (('was', 'hungry', 'so'), 18)\n",
    ">  (('The', 'result', 'is'), 17)\n",
    ">  (('looking', 'for', 'a'), 17)\n",
    ">  (('she', 'went', 'looking'), 16)\n",
    ">  (('he', 'went', 'looking'), 16)\n",
    ">  (('result', 'is', 'a'), 15)\n",
    ">  (('so', 'he', 'went'), 14)\n",
    ">  (('so', 'she', 'went'), 14)"
   ],
   "id": "5a9a2b2989bafef6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General implementation of n-gram count",
   "id": "dd23807dc001c9e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_ngram_counts(dataset: list[str], n: int) -> dict[str, Counter]:\n",
    "    \"\"\"Computes the n-gram counts from a dataset.\n",
    "    Takes a list of text strings as input,\n",
    "    constructs n-grams, and creates a dictionary where:\n",
    "        * Keys represent n-1 token long contexts `context`.\n",
    "        * Values are a Counter object `counts` such that `counts[next_token]` is the\n",
    "        * count of `next_token` following `context`.\n",
    "    Args:\n",
    "        dataset: The list of text strings in the dataset.\n",
    "        n: The size of the n-grams to generate (e.g., 2 for bigrams, 3 for\n",
    "            trigrams).\n",
    "    Returns:\n",
    "        A dictionary where keys are (n-1)-token contexts and values are Counter\n",
    "        objects storing the counts of each next token for that context.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the dictionary as a defaultdict initialized w/ empty Counter obj.\n",
    "    # This allows you to access and set value of ngram_counts[context][next_token]\n",
    "    # w/o initializing ngram_counts[context] or ngram_counts[context][next_token] first.\n",
    "\n",
    "    ngram_counts = defaultdict(Counter)\n",
    "\n",
    "    # Loop through all paragraphs.\n",
    "    for paragraph in dataset:\n",
    "        # Loop through all n-grams for the paragraph.\n",
    "        for ngram in generate_ngrams(paragraph, n):\n",
    "            # Extract the context. This will be all but the last token.\n",
    "            context = \" \".join(ngram[:-1])\n",
    "            # Extract the next token. This will be the last token of the n-gram.\n",
    "            next_token = ngram[-1]\n",
    "            # Increment the counter for the context - next_token pair by 1.\n",
    "            ngram_counts[context][next_token] += 1\n",
    "\n",
    "    return dict(ngram_counts)\n",
    "\n",
    "# Example usage of the function.\n",
    "example_data = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another example sentence.\",\n",
    "    \"Split a sentence.\"\n",
    "]\n",
    "ngram_counts = get_ngram_counts(example_data, 2)\n",
    "\n",
    "# Print the bigram counts dictionary for the dataset consisting of the\n",
    "# three example sentences.\n",
    "print(\"Bigram counts dictionary:\\n\")\n",
    "print(\"{\")\n",
    "for context, counter in ngram_counts.items():\n",
    "    print(f\"  '{context}': {counter},\")\n",
    "print(\"}\")"
   ],
   "id": "71ad17c416ee0e7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Example Output.\n",
    "Bigram counts dictionary:\n",
    ">```\n",
    ">{\n",
    ">  'This': Counter({'is': 1}),\n",
    ">  'is': Counter({'an': 1}),\n",
    ">  'an': Counter({'example': 1}),\n",
    ">  'example': Counter({'sentence.': 2}),\n",
    ">  'Another': Counter({'example': 1}),\n",
    ">  'Split': Counter({'a': 1}),\n",
    ">  'a': Counter({'sentence.': 1}),\n",
    ">}"
   ],
   "id": "2d5935f3e2116ba1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test\n",
    "# @title Run this cell to test your implementation.\n",
    "ngrams.test_ngram_counts(get_ngram_counts, generate_ngrams)"
   ],
   "id": "8b25b4676a5494d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use Pandas to create a table showing all possible n-gram counts in the Africa Galore dataset\n",
    "\n",
    "Most of the probabilities will be 0.\n",
    "For any context  A , the probability  P(B∣A)  will be 0 for most tokens  B .\n",
    "\n",
    "As the length of the context increases, the sparsity increases more (which makes sense).\n",
    "\n",
    "99.95% of bigrams never appear. 99.98% of trigrams never appear."
   ],
   "id": "3e85b88ccec61854"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# count bigrams\n",
    "bigram_counts = get_ngram_counts(dataset, n=2)\n",
    "# 99.95% never appear in the dataset.\n",
    "# There are  5,143×5,176  possible combinations.\n",
    "\n",
    "# Use the pandas library to display the counts in a table.\n",
    "bigram_counts_matrix = {\n",
    "    context: dict(counts) for context, counts in bigram_counts.items()\n",
    "}\n",
    "bigram_data_frame = pd.DataFrame.from_dict(\n",
    "    bigram_counts_matrix, orient=\"index\").fillna(0)\n",
    "\n",
    "display(bigram_data_frame)\n",
    "\n",
    "zero_count = (bigram_data_frame == 0).sum().sum()\n",
    "print(\n",
    "    f\"Number of bigrams with a count of 0: {zero_count:,}\"\n",
    "    f\" ({zero_count/bigram_data_frame.size * 100:.2f}%)\"\n",
    ")\n",
    "\n",
    "# Count trigrams\n",
    "trigram_counts = get_ngram_counts(dataset, n=3)\n",
    "# There are 13,411×5,142 possible combinations.\n",
    "# # 99.98% never appear in the dataset.\n",
    "\n",
    "# Use the pandas library to display the counts in a table.\n",
    "trigram_counts_matrix = {\n",
    "    context: dict(counts) for context, counts in trigram_counts.items()\n",
    "}\n",
    "trigram_data_frame = pd.DataFrame.from_dict(\n",
    "    trigram_counts_matrix, orient=\"index\").fillna(0)\n",
    "\n",
    "display(trigram_data_frame)\n",
    "\n",
    "zero_count = (trigram_data_frame == 0).sum().sum()\n",
    "print(\n",
    "    f\"Number of trigrams with a count of 0: {zero_count:,}\"\n",
    "    f\" ({zero_count/trigram_data_frame.size * 100:.2f}%)\"\n",
    ")"
   ],
   "id": "8d344d2f8f425580"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Calculate P(B | A)\n",
    "\n",
    "Compute the probability of any token $\\mbox{B}$ following any context $\\mbox{A}$.\n",
    "\n",
    "$$P(\\mbox{B} \\mid \\mbox{A}) = \\frac{\\mbox{Count}(\\mbox{A B})}{\\mbox{Count}(\\mbox{A})}$$\n",
    "\n",
    "Using the `get_ngram_counts` function, compute both $\\mbox{Count}(\\mbox{A B})$ and $\\mbox{Count}(\\mbox{A})$. Example: estimate probabilities of a trigram model using context of length 2, compute the counts in the numerator and the denominator for a `dataset` as:\n",
    "\n",
    "```python\n",
    "# Numerator.\n",
    "trigram_counts = get_ngram_counts(dataset, n=3)\n",
    "# Denominator.\n",
    "bigram_counts = get_ngram_counts(dataset, n=2)\n",
    "```\n",
    "\n",
    "-> Trick to compute bigram count directly from a trigram count w/o calling `get_ngram_counts()` twice.\n",
    "\n",
    "To observe how this works, consider the trigram counts for all trigrams that start with the bigram \"a staple.\" You can access these using the dictionary `trigram_counts` that is defined above:\n",
    "\n",
    "```python\n",
    "context = \"a staple\"            # searches for all trigrams beginning with \"a staple\"\n",
    "trigram_counts[context]         # returns the full trigram w/ the number of times it's repeated\n",
    "```\n",
    "\n",
    "The counter in the output of the previous cell shows you that the dataset contains the following trigrams starting with \"a staple\":\n",
    "\n",
    "* \"a staple food\" (1 time).\n",
    "* \"a staple in\" (6 times).\n",
    "* \"a staple dish\" (2 times).\n",
    "* \"a staple throughout\" (1 time).\n",
    "* \"a staple of\" (1 time).\n",
    "* \"a staple at\" (1 time).\n",
    "* \"a staple beverage\" (1 time).\n",
    "\n",
    "The trick to get the bigram count of \"a staple\" is to sum the number of trigrams that start with \"a staple.\" From the counter above, we can compute this total by summing $1+6+2+1+1+1+1 = 13$.\n",
    "\n",
    "Do this automatically using `sum()` function and `values()` method of a counter."
   ],
   "id": "20888966a89c84c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "context = \"a staple\"\n",
    "# Compute the bigram count for \"a staple\" with sum().\n",
    "bigram_count_a_staple = sum(trigram_counts[context].values())\n",
    "\n",
    "print(\n",
    "    'Bigram count of \"a staple\" computed indirectly from trigram counts: ',\n",
    "    bigram_count_a_staple,\n",
    ")\n",
    "\n",
    "# Extract the bigram count for \"a staple\" from bigram_counts.\n",
    "print('Bigram count of \"a staple\" computed directly: ',\n",
    "      bigram_counts[\"a\"][\"staple\"])"
   ],
   "id": "9b423339b70791d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Compute n-gram probabilities\n",
    "\n",
    "Return a dictionary of dictionaries w/ keys as contexts of length $n-1$ tokens and values as dictionary providing the probabilities of the next token given the context.\n",
    "\n",
    ">For example, if the dataset consists of the two sentences \"Table Mountain is tall.\" and \"Table Mountain is beautiful.\" then the function called with `n = 3` should return:\n",
    ">```\n",
    ">{\n",
    ">   \"Table Mountain\": {\"is\": 1.0},\n",
    ">   \"Mountain is\": {\"tall\": 0.5, \"beautiful\": 0.5}\n",
    ">}\n"
   ],
   "id": "9bf3a2519dbcd2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_ngram_model(dataset: list[str], n: int) -> dict[str, dict[str, float]]:\n",
    "    \"\"\"Builds an n-gram language model.\n",
    "    Takes a list of text strings,\n",
    "    generates n-grams from each text using get_ngram_counts,\n",
    "    and converts them into probabilities.\n",
    "    The resulting model is a dictionary,\n",
    "    where keys are (n-1)-token contexts and values are dictionaries mapping\n",
    "    possible next tokens to their conditional probabilities given the context.\n",
    "\n",
    "    Args:\n",
    "        dataset: A list of text strings representing the dataset.\n",
    "        n: The size of the n-grams (e.g., 2 for a bigram model).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary representing the n-gram language model, where keys are\n",
    "        (n-1)-tokens contexts and values are dictionaries mapping possible next\n",
    "        tokens to their conditional probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # A dictionary to store P(B | A).\n",
    "    # ngram_model[context][token] should store P(token | context).\n",
    "    ngram_model = {}\n",
    "\n",
    "    # Use the ngram_counts as computed by the get_ngram_counts function.\n",
    "    ngram_counts = get_ngram_counts(dataset, n)\n",
    "\n",
    "    # Loop through the possible contexts. `context` is a string\n",
    "    # and `next_tokens` is a dictionary mapping possible next tokens to their\n",
    "    # counts of following `context`.\n",
    "    for context, next_tokens in ngram_counts.items():\n",
    "\n",
    "        # Compute Count(A) and P(B | A ) here.\n",
    "        context_total_count = sum(next_tokens.values())\n",
    "        ngram_model[context] = {}\n",
    "        for token, count in next_tokens.items():\n",
    "            ngram_model[context][token] = count / context_total_count\n",
    "\n",
    "    return ngram_model\n",
    "\n",
    "# Test the method above by bulding a simple trigram model.\n",
    "test_dataset = [\"Table Mountain is tall.\", \"Table Mountain is beautiful.\"]\n",
    "test_trigram_model = build_ngram_model(test_dataset, n=3)\n",
    "test_trigram_model"
   ],
   "id": "fa6d755db7dc740c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title Run this cell to test your implementation.\n",
    "ngrams.test_build_ngram_model(build_ngram_model, get_ngram_counts)"
   ],
   "id": "fcc26945f14d98db"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Now construct a trigram model!",
   "id": "b131e5cc4cd4a152"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trigram_model = build_ngram_model(dataset, n=3)\n",
    "\n",
    "# To gain an understanding of the patterns that the model learned, inspect a few probability distributions.\n",
    "print(f\"P(B | \\\"as it\\\") = {trigram_model['as it']}\")\n",
    "\n",
    "print(f\"P(B | \\\"as they\\\") = {trigram_model['as they']}\")"
   ],
   "id": "f27adb7ab7d2d0f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Expected output\n",
    ">```\n",
    "> P(B | \"as it\") = {'is': 0.6666666666666666, 'receives': 0.3333333333333333}\n",
    "> P(B | \"as they\") = {'were': 1.0}"
   ],
   "id": "b2fe1d9e5532fc8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### More possible contexts",
   "id": "17666f40e2e1e4aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "context = \"The name\"\n",
    "trigram_model[context]\n",
    "# {'means': 0.6666666666666666, \"'Etosha'\": 0.3333333333333333}\n",
    "\n",
    "context = \"Their name\"\n",
    "trigram_model[context]\n",
    "# Will receive a [key error] b/c the phrase does not exist."
   ],
   "id": "c7adb56de7926a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting it to use!\n",
    "Now that we know the probabilities, predict the next token!"
   ],
   "id": "7151345df94e6a71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example\n",
    "# Manually define a list of tokens & use probability distribution to weight the results.\n",
    "example_candidate_tokens = [\"apple\", \"banana\", \"cherry\"]\n",
    "\n",
    "# Define corresponding probabilities for each fruit.\n",
    "fruit_probabilities = [0.2, 0.5, 0.3]\n",
    "\n",
    "# Sample one fruit based on the probabilities.\n",
    "# The 'k=1' parameter instructs the function to return one item.\n",
    "chosen_fruit = random.choices(\n",
    "    example_candidate_tokens,\n",
    "    weights=fruit_probabilities,\n",
    "    k=1)[0]\n",
    "\n",
    "print(\"Chosen fruit:\", chosen_fruit)"
   ],
   "id": "58c729b1ee7db29b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# The real task\n",
    "context = \"looking for\"\n",
    "candidate_tokens = []\n",
    "candidate_tokens_probabilities = []\n",
    "\n",
    "# Extract candidate tokens and associated probabilities from `trigram_model`.\n",
    "for token, prob in trigram_model[context].items():\n",
    "    candidate_tokens.append(token)\n",
    "    candidate_tokens_probabilities.append(prob)\n",
    "\n",
    "print(f\"Candidate tokens: {candidate_tokens}\")\n",
    "print(f\"Candidate token probabilities: {candidate_tokens_probabilities}\")\n",
    "\n",
    "# Sample from the list of candidate tokens according to the\n",
    "# associated probabilities.\n",
    "next_token = random.choices(candidate_tokens,\n",
    "                            weights=candidate_tokens_probabilities)[0]\n",
    "\n",
    "print(\"\\n\\nSampled next token:\", context, next_token)"
   ],
   "id": "f4e5ff167826eca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sample output:\n",
    "\n",
    "Candidate tokens: ['the', 'a', 'Banku', 'Tella,', 'Maafe,', 'Umqombothi,', 'sugarcane', 'crispy', 'warm', 'Doro', 'sambusa,', 'dodo,', 'Fura']\n",
    "\n",
    "Candidate token probabilities: [0.125, 0.53125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125]\n",
    "\n",
    "\n",
    "Sampled next token: looking for Banku"
   ],
   "id": "1140792929a2d979"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate new texts for prompt using n-gram model.\n",
    "\n",
    "Text generation using an n-gram model is an iterative process where each newly generated token is added to the existing context. This forms the basis for predicting the next token.\n",
    "\n",
    "Starting with an initial prompt text, the model uses the probability distribution derived from the n-gram counts to select the most likely next token. This again makes use of the `random.choices` function for picking the next token. Once this token has been generated, it is added to the context and the updated sequence is used to calculate the next probability distribution. This chain-like process continues until `num_tokens_to_generate` tokens have been generated.\n",
    "\n",
    "The following `generate_next_n_tokens` function implements this iterative generation process:"
   ],
   "id": "7211a2ebfa04f706"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_next_n_tokens(\n",
    "    n: int,\n",
    "    ngram_model: dict[str, dict[str, float]],\n",
    "    prompt: str,\n",
    "    num_tokens_to_generate: int,\n",
    ") -> str:\n",
    "    \"\"\"Generates `num_tokens_to_generate` tokens for a prompt using\n",
    "    an n-gram model.\n",
    "\n",
    "    Uses n-gram model to predict most likely next token for prompt.\n",
    "    The generation process continues, appending predicted tokens to prompt\n",
    "    until the desired number of tokens is generated or a context is\n",
    "    encountered for which the model has no predictions.\n",
    "\n",
    "    Args:\n",
    "        n: The size of the n-grams.\n",
    "        ngram_model: A dictionary representing the n-gram model.\n",
    "        prompt: Starting text prompt.\n",
    "        num_tokens_to_generate: The number of words to generate after prompt.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the original prompt followed by the generated\n",
    "        tokens. If no valid continuation is found for a given context, the\n",
    "        function will return the text generated up to that point and print a\n",
    "        message indicating that no continuation could be found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split prompt into individual tokens.\n",
    "    generated_words = create_tokens(prompt)\n",
    "\n",
    "    for _ in range(num_tokens_to_generate):\n",
    "        # Get last (n-1) tokens as context.\n",
    "        context = generated_words[-(n - 1):]\n",
    "        context = \" \".join(context)\n",
    "        if context in ngram_model:\n",
    "            # Sample next word based on probabilities.\n",
    "            next_word = random.choices(\n",
    "                list(ngram_model[context].keys()),\n",
    "                weights=ngram_model[context].values()\n",
    "            )[0]\n",
    "\n",
    "            generated_words.append(next_word)\n",
    "        else:\n",
    "            print(\n",
    "                \"⚠️ No valid continuation found. Change the prompt or\"\n",
    "                \" try sampling another continuation.\\n\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    return \" \".join(generated_words)"
   ],
   "id": "82861a4aa2fe9d1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Bigram\n",
    "\n",
    "Expected output will begin intelligently, but quickly devolve.\n",
    "```\n",
    "Jide was hungry so she went looking for hours, would fill with ground and they pounded, Nana Yaa,"
   ],
   "id": "b4c718760aceb3ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"Jide was hungry so she went looking for\"\n",
    "\n",
    "# Construct a bigram model using the Africa Galore dataset.\n",
    "bigram_model = build_ngram_model(dataset, n=2)\n",
    "\n",
    "n = 2  # Bigram.\n",
    "num_tokens_to_generate = 10  # Generate next n words.\n",
    "generate_next_n_tokens(\n",
    "    n=n,\n",
    "    ngram_model=bigram_model,\n",
    "    prompt=prompt,\n",
    "    num_tokens_to_generate=num_tokens_to_generate,\n",
    ")"
   ],
   "id": "4a68bde575e28773"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Trigram\n",
    "\n",
    "Expected output will take longer to devolve\n",
    "```\n",
    "Jide was hungry so she went looking for Umqombothi, a traditional Malian couscous dish made from the Tswana"
   ],
   "id": "563a76f616e49385"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"Jide was hungry so she went looking for\"\n",
    "\n",
    "n = 3  # Trigram.\n",
    "num_tokens_to_generate = 10  # Generate next n words.\n",
    "generate_next_n_tokens(\n",
    "    n=n,\n",
    "    ngram_model=trigram_model,\n",
    "    prompt=prompt,\n",
    "    num_tokens_to_generate=num_tokens_to_generate,\n",
    ")"
   ],
   "id": "2e07241dd81e3b8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Much larger N-grams\n",
    "\n",
    "As **n** increases, the number of mathematically possible combinations increases exponentially; however, the number of combinations that are statistically likely to occur increases linearly. For example, \"I went to the movies with my mom,\" has\n",
    "- 47 possible bigrams\n",
    "- 339 possible trigrams\n",
    "\n",
    "However, many combinations never occur in practice. The probability of the following occurring is statistically **0**.\n",
    "- \"movies the\"\n",
    "- \"to mom\"\n",
    "- \"to went I\"\n"
   ],
   "id": "8b76253737b9bede"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
